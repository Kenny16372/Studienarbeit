{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kostenfunktion (loss function)\n",
    "## Categorical Crossentropy\n",
    "Dieses Notebook enthält die Kostenfunktion Categorical Crossentropy. Sie ist sinnvoll, um Wahrscheinlichkeitsverteilungen zu vergleichen. Im Beispiel von CNNs wird diese Funktion dafür eingesetzt, um zu testen, wie unterschiedlich der Output des Netzwerks von dem Zielwert ist, also der Vergleich von einer Klasse gegenüber allen anderen. Die Formel lautet\n",
    "$$Loss=-\\sum_j{y_j\\cdot \\log{\\hat{y}_j}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code - Beispiele für Categorical Crossentropy\n",
    "Der folgende Codeabschnitt zeigt das Ergebnis der Kostenfunktion für verschiedene Inputs. Die Anzahl der Klassen ist auf $4$ begrenzt, um sie gut anzeigen zu können. Im Output zu erkennen ist, dass der absolute Wert der Kostenfunktion mit steigender Annäherung an den Zielvektor immer kleiner wird.\n",
    "### Implementierung der Funktion\n",
    "Die Summe wird durch das Skalarprodukt des Zielvektors und der Schätzung gebildet. Der Logarithmus des Schätzungsvektors wird auf ein masked array angewendet und dann wieder mit dem Wert $0$ aufgefüllt, um die Division durch $0$ zu vermeiden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Vector:  [0, 0, 1, 0]\n",
      "Loss for [0.25, 0.25, 0.25, 0.25]: 1.3862943611198906\n",
      "Loss for [0.0, 0.5, 0.5, 0.0]: 0.6931471805599453\n",
      "Loss for [-0.1, -0.1, 1.2, 0.0]: -0.1823215567939546\n",
      "Loss for [0, 0, 1, 0]: -0.0\n"
     ]
    }
   ],
   "source": [
    "def categorical_crossentropy(Y, Yhat):\n",
    "    return -np.dot(Y, np.ma.log(Yhat).filled(0))\n",
    "\n",
    "target = [0,0,1,0]\n",
    "print(\"Target Vector: \", target)\n",
    "estimate = [0.25,0.25,0.25,0.25]\n",
    "print(f\"Loss for {estimate}: {categorical_crossentropy(target, estimate)}\")\n",
    "estimate = [0.0,0.5,0.5,0.0]\n",
    "print(f\"Loss for {estimate}: {categorical_crossentropy(target, estimate)}\")\n",
    "estimate = [-0.1,-0.1,1.2,0.0]\n",
    "print(f\"Loss for {estimate}: {categorical_crossentropy(target, estimate)}\")\n",
    "estimate = [0,0,1,0]\n",
    "print(f\"Loss for {estimate}: {categorical_crossentropy(target, estimate)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
