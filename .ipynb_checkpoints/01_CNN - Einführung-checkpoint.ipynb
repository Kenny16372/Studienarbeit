{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einführung in Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klärung von Begrifflichkeiten\n",
    "- Die Schichten eines neuronalen Netzwerks werden entweder als **Schicht** oder als **Layer** (englisch) bezeichnet\n",
    "- Die Knoten in einer Schicht entweder als **Knoten** oder als **Node** (englisch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Das Ziel eines CNNs\n",
    "CNNs ermöglichen es, KI auf Bilder oder Audio anzuwenden. Mögliche Anwendungsgebiete sind:\n",
    "- Objekterkennung\n",
    "- Bildsegmentierung\n",
    "- Gesichtserkennung\n",
    "- Spracherkennung\n",
    "- ...\n",
    "\n",
    "Diese Serie von Jupyter Notebooks wird sich auf die **Klassifizierung** beschränken, am Beispiel der Datensätze **MNIST**, **German Traffic Sign** und **Street View House Number**. <a href=\"http://yann.lecun.com/exdb/mnist/\">MNIST</a> enthält Schwarz-Weiß-Bilder von handschriftlichen Ziffern, <a href=\"https://www.kaggle.com/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\">German Traffic Sign</a> besteht aus Bildern von Straßenschildern aus Deutschland und <a href=\"http://ufldl.stanford.edu/housenumbers/\">Street View House Number</a> enthält Bilder von Hausnummern, die aus Google Steet View extrahiert wurden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unterschied zu „klassischen“ neuronalen Netzwerken\n",
    "### Mehrdimensionale Layer\n",
    "In „klassischen“ neuronalen Netzwerken ist der Input zu einem bestimmten Layer eindimensional: er besteht aus dem Output der vorhergehenden Knoten, d. h. bei $n$ Knoten können die Daten, die zwischen den Layern übergeben werden, als $n\\times1$-Matrix ($nD$-Vektor) repäsentiert werden. Gleiches gilt für die Gewichte eines Knotens des Folgelayers (unter der Annahme, dass das Netzwerk vollständig verknüpft ist, d. h. jeder Knoten auf alle Knoten des nachfolgenden Layers Einfluss hat). <br>\n",
    "Anschauliche Erklärung anhand eines Beispiels:\n",
    "<div style=\"width:40%;margin:auto;margin-top:20px\">\n",
    "<img src=\"assets/Neural_Network.svg\" alt=\"Aufbau eines simplen neuronalen Netzwerks\"/>\n",
    "<small style=\"text-align:right;display:block\"><a href=\"https://de.wikipedia.org/w/index.php?title=K%C3%BCnstliches_neuronales_Netz&oldid=204504686\">Quelle</a></small>\n",
    "    <div style=\"text-align:center;color:RGB(117,117,117)\">Aufbau eines simplen neuronalen Netzwerks</div>\n",
    "</div>\n",
    "In der mittleren Schicht erhält jede Node zwei Inputwerte: die Outputs der Nodes in der vorhergehenden Schicht. Jede Node gibt exakt einen Wert aus, deswegen gibt es für jeden Knoten der mittleren Schicht immer zwei Inputwerte, die als 2D-Vektor geschrieben werden. Mit jedem dieser Werte assoziiert der folgende Knoten genau ein Gewicht, sodass folgt, dass alle Knoten des mittleren Layers 2D-Gewichte haben.\n",
    "<div style=\"width:70%;margin:auto;margin-top:20px\">\n",
    "<img src=\"assets/CNN.jpeg\" alt=\"Aufbau eines CNNs\"/>\n",
    "<small style=\"text-align:right;display:block\"><a href=\"https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\">Quelle</a></small>\n",
    "    <div style=\"text-align:center;color:RGB(117,117,117)\">Aufbau eines Convolutional Neural Networks</div>\n",
    "</div>\n",
    "Farbbilder werden in Computern als dreidimensionale Arrays repräsentiert:$$(Breite)\\times(Höhe)\\times(Farbtiefe)$$\n",
    "In der Abbildung oben wird dies links, beim Inputlayer, angedeutet.<br>\n",
    "Wenn jetzt ein Bild in einem Layer „verarbeitet“ wird (der genaue Prozess folgt unten), dann gibt es keine einzelnen Werte mehr, die von Schicht zu Schicht fließen, sondern es wird im vorderen Teil des CNNs immer ein Bild übergeben. Die Bezeichnung für das, was zwischen den Schichten übermittelt wird, ändert sich jedoch nach ab dem ersten Verarbeitungsschritt zu <b>Feature Map</b>, um anzudeuten, dass bestimmte Merkmale des Bildes verstärkt hervorgehoben wurden.<br>\n",
    "Weil der Input zu einer Schicht nicht mehr aus Zahlen besteht, sondern aus dreidimensionalen Gebilden, müssen die Gewichte auch dreidimensional sein. Eine weitere Einschränkung gibt es, und zwar muss die Farb- bzw. Bittiefe der Gewichte mit der des Bildes bzw. der Feature Map übereinstimmen. Weiterhin werden die Gewichte im vorderen Teil des CNNs nicht Gewichte, sondern <b>Kernel</b> genannt.\n",
    "<h3>Geteilte Gewichte</h3>\n",
    "Eine weitere Besonderheit von CNNs ist, dass für jeden Layer nur ein Kernel existiert. Dieser wird auf alle Ausschnitte des Bildes / der Feature Map angewandt. Somit wird die Anzahl der Gewichte deutlich eingeschränkt.<br>\n",
    "Zur Veranschaulichung ein Beispiel:<br>\n",
    "Verbindet man jeden ausgehenden Pixel eines Layers mit jedem Knoten des nächsten, hat man bei einer $100\\times 100$ Pixel Feature Map (Graustufen) <i>pro Knoten</i> $10.000$ Gewichte.<br>\n",
    "Im Vergleich dazu hat ein $3\\times 3$-Kernel $9$ Werte als Gewichte.<br>\n",
    "Das hat zur Folge, dass das Netzwerk aus mehr Layern bestehen kann, die zusammengenommen komplexe Features erkennen können. Weiter wird dadurch das Netzwerk weniger anfällig für <i>Overfitting</i>.\n",
    "<h3>Lokale Konnektivität</h3>\n",
    "Die Verwendung von Kernels anstelle vollständig verbundener Schichten hat außerdem einen weiteren Vorteil. Da der Kernel immer mehrere Pixel bedeckt, werden lokale Beziehungen zwischen diesen Pixeln stark berücksichtigt. Das ist bei vollständig verbundenen Schichten ebenfalls möglich, aber in diesem Fall muss das Verhalten erst erlernt werden, und ist nicht durch das Design gegeben. Somit würde die Dauer der Trainingsphase bis zur Konvergenz länger sein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktionsweise\n",
    "In diesem Abschnitt wird erklärt, wie ein CNN funktioniert. Es wird jedoch nicht auf Implementierungsdetails eingegagen. Die folgende Abbildung, die oben bereits stand und hier zur Veranschaulichung erneut abgedruckt ist, wird zur Referenz hergenommen.\n",
    "<div style=\"width: 70% ; margin: auto; margin-top:20px\">\n",
    "<img src=\"assets/CNN.jpeg\" alt=\"Aufbau eines CNNs\">\n",
    "<small style=\"text-align: right ; display: block\"><a href=\"https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\" target=\"_blank\">Quelle</a></small>\n",
    "    <div style=\"text-align: center ; color: rgb(117 , 117 , 117)\">Aufbau eines Convolutional Neural Networks</div>\n",
    "</div>\n",
    "Ein CNN lässt sich in zwei Teile aufteilen, das Feature Learning und die Klassifizierung.\n",
    "<h3>Feature Learning</h3>\n",
    "Im vorderen Teil des CNNs, dem Feature Learning, werden durch die Konvolution mit den Kernels der Layer bestimmte Merkmale erkannt, die das Netzwerk selbst festlegt. Das bedeutet zum Beispiel, dass eine Schicht Kanten detektiert, und die folgende dann aus diesen beispielsweise Ecken erkennt. Im Feature Learning gibt es zwei verschiedene Arten von Schichten, Konvolutions- und Poolingschichten. Bei der Konvolution wird auf eine Feature Map ein Kernel angewandt, während beim Pooling die Größe der Feature Map verkleinert wird.\n",
    "<h4>Konvolutionsschicht</h4>\n",
    "<div style=\"width: 70% ; margin: auto;margin-top: 20px;margin-bottom: 20px;\">\n",
    "<img src=\"assets/convolution.gif\" alt=\"Funktionsweise der Konvolution\">\n",
    "<small style=\"text-align: right ; display: block\"><a href=\"https://towardsdatascience.com/lets-code-convolutional-neural-network-in-plain-numpy-ce48e732f5d5\" target=\"_blank\">Quelle</a></small>\n",
    "    <div style=\"text-align: center ; color: rgb(117 , 117 , 117)\">Veranschaulichung der Konvolution. Der verwendete Kernel detektiert horizontale Kanten</div>\n",
    "</div>\n",
    "Anschaulich wird bei der Konvolution das Inputbild (bzw. die Feature Map) hergenommen und der Kernel darüber geschoben. Für jeden Schritt wird der Kernel mit dem Teil des Bildes, den er bedeckt, multipliziert. Diese Werte werden addiert und ergeben den neuen Pixelwert.<br>\n",
    "In der Abbildung oben ist eine beispielhafte Konvolution dargestellt. Der verwendete $3\\times 3$-Kernel dient zur Detektion von horizontalen Kanten und wird auch <a href=\"https://de.wikipedia.org/w/index.php?title=Sobel-Operator&oldid=204090356\">Sobel-Operator</a> genannt. In einem späteren Notebook zu den Layern wird die Konvolution auf einem tieferen Level erklärt.\n",
    "<h3>Poolingschicht</h3>\n",
    "In einer Poolingschicht werden die Dimensionen einer Feature Map verkleinert. Das geschieht, indem wieder ein Teilbereich betrachtet wird, und ein einzelner Pixelwert aus diesem Bereich generiert wird.<br>\n",
    "Der Unterschied zur Konvolution ist, dass anstelle des Kernels eine <b>unveränderliche Funktion</b> verwendet wird. Mögliche Funktionen sind die <b>Max</b>-Funktion und die <b>Average</b>-Funktion. Die erste gibt den Maximalwert zurück, während letztere den Mittelwert des Bereichs zurückgibt. Ein weiterer Unterschied ist, dass der Teilbereich so verschoben wird, dass sich <b>keine zwei Teilbereiche überlappen</b> (Schrittweite $>1$). In der folgenden Abbildung ist eine beispielhafte Poolingschicht dargestellt. Der untere Teil der Abbildung (Backward Pass) ist jetzt noch nicht wichtig und wird später erklärt.\n",
    "<div style=\"width: 70% ; margin: auto;margin-top: 20px;margin-bottom: 20px;\">\n",
    "    <img src=\"assets/pooling.gif\" alt=\"Funktionsweise des Poolings\">\n",
    "    <small style=\"text-align: right ; display: block\">\n",
    "        <a href=\"https://towardsdatascience.com/lets-code-convolutional-neural-network-in-plain-numpy-ce48e732f5d5\" target=\"_blank\">Quelle</a>\n",
    "    </small>\n",
    "        <div style=\"text-align: center ; color: rgb(117 , 117 , 117)\">Veranschaulichung des Max-Poolings</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "Der hintere Teil des CNNs hat das Ziel, aus den erlernten Merkmalen auf die richtige Klasse zu schließen. Hierfür wird ein vollständig verbundenes neuronales Netzwerk verwendet.<br>\n",
    "Zuerst werden die mehrdimensionalen Feature Maps zu einem großen Vektor umgewandelt, der dann weiterverarbeitet werden kann. <br>\n",
    "Der Rest des Klassifikations-Netzwerks wird hier nicht erklärt, da dies ein standardmäßiges neuronales Netzwerk zur Klassifizierung ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quellen\n",
    "https://de.wikipedia.org/w/index.php?title=Convolutional_Neural_Network&oldid=208220229<br>\n",
    "https://towardsdatascience.com/simple-introduction-to-convolutional-neural-networks-cdf8d3077bac<br>\n",
    "https://towardsdatascience.com/understanding-parameter-sharing-or-weights-replication-within-convolutional-neural-networks-cc26db7b645a<br>\n",
    "https://towardsdatascience.com/understanding-cnn-convolutional-neural-network-69fd626ee7d4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
